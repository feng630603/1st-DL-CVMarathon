{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##PTT 網路爬蟲實作練習\n",
    "#能夠利用 Request + BeatifulSour 撰寫爬蟲，並存放到合適的資料結構\n",
    "#作業目標\n",
    "#根據範例 ，完成以下問題：\n",
    "\n",
    "#① 印出最新文章的「作者」「標題」「時間」\n",
    "#② 印出第一頁所有文章的「作者」「標題」「時間」\n",
    "#③ 試著爬爬看其他版的文章"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'https://www.ptt.cc/bbs/Stock/index.html'\n",
    "r = requests.get(url)\n",
    "\n",
    "soup = BeautifulSoup(r.text, \"html5lib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "標題：  [標的] 宏捷科 8086 多\n",
      "作者：  lantha523\n",
      "時間：   8/25\n",
      "標題：  4-2-3(已被BreezeCat刪除) <OoShiunoO>\n",
      "作者：  -\n",
      "時間：   8/25\n",
      "標題：  4-2-1(已被BreezeCat刪除) <a1019>\n",
      "作者：  -\n",
      "時間：   8/25\n",
      "標題：  [新聞] 台積電技術論壇 魏哲家：3奈米明年試產\n",
      "作者：  hvariables\n",
      "時間：   8/25\n",
      "標題：  (本文已被刪除) [homura456]\n",
      "作者：  -\n",
      "時間：   8/25\n",
      "標題：  Re: [請益] 中國為何不全力反制美國？\n",
      "作者：  alanwon\n",
      "時間：   8/25\n",
      "標題：  4-2-3(已被BreezeCat刪除) <lonnan>\n",
      "作者：  -\n",
      "時間：   8/25\n",
      "標題：  [新聞] 透過數據中心與軟體事業來改變企業核心，\n",
      "作者：  zxcvxx\n",
      "時間：   8/25\n",
      "標題：  [閒聊] 2020/08/25 盤後閒聊\n",
      "作者：  zesonpso\n",
      "時間：   8/25\n",
      "標題：  [新聞] 兩岸情勢升溫 中官媒突溫情喊話?!\n",
      "作者：  pharmacist05\n",
      "時間：   8/25\n",
      "標題：  [新聞] 高雄銀攜路博邁 疫後投資開講\n",
      "作者：  yoche2000\n",
      "時間：   8/25\n",
      "標題：  [請益] 王道銀行 開發金\n",
      "作者：  nike80495\n",
      "時間：   8/25\n",
      "標題：  [公告] Stock 板規V2.7\n",
      "作者：  eyespot\n",
      "時間：  11/03\n",
      "標題：  [公告] 股票板板主徵選公告 \n",
      "作者：  BreezeCat\n",
      "時間：   8/11\n",
      "標題：  [公告] 精華區導覽Q&A\n",
      "作者：  IanLi\n",
      "時間：   1/25\n",
      "標題：  [閒聊] 2020/08/25 盤後閒聊\n",
      "作者：  zesonpso\n",
      "時間：   8/25\n"
     ]
    }
   ],
   "source": [
    "#② 印出第一頁所有文章的「作者」「標題」「時間」\n",
    "# 方法一：只從首頁\n",
    "for d in soup.find_all(class_=\"r-ent\"):\n",
    "    print('標題： ', d.find(class_='title').text.replace('\\t', '').replace('\\n', ''))\n",
    "    print('作者： ', d.find(class_='author').text.replace('\\t', '').replace('\\n', ''))\n",
    "    print('時間： ', d.find(class_='date').text.replace('\\t', '').replace('\\n', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "標題：  [標的] 宏捷科 8086 多\n",
      "作者： lantha523 (lantha)\n",
      "時間： Tue Aug 25 12:35:33 2020\n",
      "標題：  4-2-3(已被BreezeCat刪除) <OoShiunoO>\n",
      "標題：  4-2-1(已被BreezeCat刪除) <a1019>\n",
      "標題：  [新聞] 台積電技術論壇 魏哲家：3奈米明年試產\n",
      "作者： hvariables (Speculative Male)\n",
      "時間： Tue Aug 25 12:47:52 2020\n",
      "標題：  (本文已被刪除) [homura456]\n",
      "標題：  Re: [請益] 中國為何不全力反制美國？\n",
      "作者： alanwon (SiuyoFabierre)\n",
      "時間： Tue Aug 25 12:59:12 2020\n",
      "標題：  4-2-3(已被BreezeCat刪除) <lonnan>\n",
      "標題：  [新聞] 透過數據中心與軟體事業來改變企業核心，\n",
      "作者： zxcvxx (zxcvxx)\n",
      "時間： Tue Aug 25 13:55:39 2020\n",
      "標題：  [閒聊] 2020/08/25 盤後閒聊\n",
      "作者： zesonpso (幹 正義的孩子王)\n",
      "時間： Tue Aug 25 14:00:02 2020\n",
      "標題：  [新聞] 兩岸情勢升溫 中官媒突溫情喊話?!\n",
      "作者： pharmacist05 (嘉南105)\n",
      "時間： Tue Aug 25 14:04:10 2020\n",
      "標題：  [新聞] 高雄銀攜路博邁 疫後投資開講\n",
      "作者： yoche2000 (九龍塘麵包粉)\n",
      "時間： Tue Aug 25 14:12:04 2020\n",
      "標題：  [請益] 王道銀行 開發金\n",
      "作者： nike80495 (阿龐)\n",
      "時間： Tue Aug 25 14:16:45 2020\n",
      "標題：  [公告] Stock 板規V2.7\n",
      "標題：  [公告] 股票板板主徵選公告 \n",
      "作者： BreezeCat (微風)\n",
      "時間： Tue Aug 11 21:22:16 2020\n",
      "標題：  [公告] 精華區導覽Q&A\n",
      "作者： IanLi (IanLi)\n",
      "時間： Sun Jan 25 23:18:20 2015\n",
      "標題：  [閒聊] 2020/08/25 盤後閒聊\n",
      "作者： zesonpso (幹 正義的孩子王)\n",
      "時間： Tue Aug 25 14:00:02 2020\n"
     ]
    }
   ],
   "source": [
    "# 方法二：進入內頁抓\n",
    "for d in soup.find_all(class_=\"title\"):\n",
    "    try:\n",
    "        print('標題： ', d.text.replace('\\t', '').replace('\\n', ''))\n",
    "        r = BeautifulSoup(requests.get('https://www.ptt.cc'+d.find('a')['href']).text, \"html5lib\")\n",
    "        print('作者： ' + r.find(class_='article-meta-value').text)\n",
    "        print('時間： ' + r.find_all(class_='article-meta-value')[-1].text)\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'標題': '[請益] 王道銀行 開發金',\n",
       " '作者': 'nike80495 (阿龐)',\n",
       " '時間': 'Tue Aug 25 14:16:45 2020'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#① 印出最新文章的「作者」「標題」「時間」\n",
    "# 因為原始的資料難以判斷「新/舊」，因此我們必須進入內頁抓取詳細的時間，最終存成 List of Dict 的形式再自行排序。\n",
    "\n",
    "posts = []\n",
    "\n",
    "for d in soup.find_all(class_=\"title\"):\n",
    "    try:\n",
    "        post = {}\n",
    "        post['標題'] = d.text.replace('\\t', '').replace('\\n', '')\n",
    "        \n",
    "        r = BeautifulSoup(requests.get('https://www.ptt.cc'+d.find('a')['href']).text, \"html5lib\")\n",
    "        post['作者'] = r.find(class_='article-meta-value').text\n",
    "        post['時間'] = r.find_all(class_='article-meta-value')[-1].text\n",
    "        \n",
    "        posts.append(post)\n",
    "    except:\n",
    "        continue\n",
    "        \n",
    "posts = sorted(posts, key= lambda x: x['時間'])\n",
    "# 補充：List of Dict 的排序方法\n",
    "# https://stackoverflow.com/questions/72899/how-do-i-sort-a-list-of-dictionaries-by-a-value-of-the-dictionary\n",
    "posts[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'標題': '[公告] 農遊/客庄/藝fun/動滋券集中討論文',\n",
       " '作者': 'medama ( )',\n",
       " '時間': 'Wed Jul 22 00:09:16 2020'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#③ 試著爬爬看其他版的文章\n",
    "# 改成 Lifeismoney 版，抓出最新一筆的文章\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'https://www.ptt.cc/bbs/Lifeismoney/index.html'\n",
    "r = requests.get(url)\n",
    "\n",
    "soup = BeautifulSoup(r.text, \"html5lib\")\n",
    "\n",
    "posts = []\n",
    "\n",
    "for d in soup.find_all(class_=\"title\"):\n",
    "    try:\n",
    "        post = {}\n",
    "        post['標題'] = d.text.replace('\\t', '').replace('\\n', '')\n",
    "        \n",
    "        r = BeautifulSoup(requests.get('https://www.ptt.cc'+d.find('a')['href']).text, \"html5lib\")\n",
    "        post['作者'] = r.find(class_='article-meta-value').text\n",
    "        post['時間'] = r.find_all(class_='article-meta-value')[-1].text\n",
    "        \n",
    "        posts.append(post)\n",
    "    except:\n",
    "        continue\n",
    "        \n",
    "posts = sorted(posts, key= lambda x: x['時間'])\n",
    "posts[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-eb815f4229b9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[0mposts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mposts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'時間'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m \u001b[0mposts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# 改成 Gossiping 版，發生錯誤，因為八卦版會跳轉到一個「十八歲的同意驗證頁面」導致錯誤。\n",
    "\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'https://www.ptt.cc/bbs/Gossiping/index.html'\n",
    "r = requests.get(url)\n",
    "\n",
    "soup = BeautifulSoup(r.text, \"html5lib\")\n",
    "\n",
    "posts = []\n",
    "\n",
    "for d in soup.find_all(class_=\"title\"):\n",
    "    try:\n",
    "        post = {}\n",
    "        post['標題'] = d.text.replace('\\t', '').replace('\\n', '')\n",
    "        \n",
    "        r = BeautifulSoup(requests.get('https://www.ptt.cc'+d.find('a')['href']).text, \"html5lib\")\n",
    "        post['作者'] = r.find(class_='article-meta-value').text\n",
    "        post['時間'] = r.find_all(class_='article-meta-value')[-1].text\n",
    "        \n",
    "        posts.append(post)\n",
    "    except:\n",
    "        continue\n",
    "        \n",
    "posts = sorted(posts, key= lambda x: x['時間'])\n",
    "posts[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'標題': '[公告] 八卦板板規(2020.07.21)',\n",
       " '作者': 'seabox (盒盒)',\n",
       " '時間': 'Tue Jul 21 00:00:04 2020'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 改成 Gossiping 版，發生錯誤，因為八卦版會跳轉到一個「十八歲的同意驗證頁面」導致錯誤。\n",
    "# 參考圖片下載時的解法，加上 cookies 繞過驗證（後面課程會再進行補充）\n",
    "\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'https://www.ptt.cc/bbs/Gossiping/index.html'\n",
    "r = requests.get(url, cookies={'over18': '1'})\n",
    "\n",
    "soup = BeautifulSoup(r.text, \"html5lib\")\n",
    "\n",
    "posts = []\n",
    "\n",
    "for d in soup.find_all(class_=\"title\"):\n",
    "    try:\n",
    "        post = {}\n",
    "        post['標題'] = d.text.replace('\\t', '').replace('\\n', '')\n",
    "        \n",
    "        r = BeautifulSoup(requests.get('https://www.ptt.cc'+d.find('a')['href'], cookies={'over18': '1'}).text, \"html5lib\")\n",
    "        post['作者'] = r.find(class_='article-meta-value').text\n",
    "        post['時間'] = r.find_all(class_='article-meta-value')[-1].text\n",
    "        \n",
    "        posts.append(post)\n",
    "    except:\n",
    "        continue\n",
    "        \n",
    "posts = sorted(posts, key= lambda x: x['時間'])\n",
    "posts[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-f3f4ed56d81d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[0mposts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mposts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'時間'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m \u001b[0mposts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# 我們發現這個時間好像不是正確的，原因是我們前面存到的時間，其實不是正確的格式\n",
    "\n",
    "# 改成 Gossiping 版，發生錯誤，因為八卦版會跳轉到一個「十八歲的同意驗證頁面」導致錯誤。\n",
    "# 參考圖片下載時的解法，加上 cookies 繞過驗證（後面課程會再進行補充）\n",
    "\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'https://www.ptt.cc/bbs/Gossiping/index.html'\n",
    "r = requests.get(url, cookies={'over18': '1'})\n",
    "\n",
    "soup = BeautifulSoup(r.text, \"html5lib\")\n",
    "\n",
    "posts = []\n",
    "\n",
    "for d in soup.find_all(class_=\"title\"):\n",
    "    try:\n",
    "        post = {}\n",
    "        post['標題'] = d.text.replace('\\t', '').replace('\\n', '')\n",
    "        \n",
    "        r = BeautifulSoup(requests.get('https://www.ptt.cc'+d.find('a')['href'], cookies={'over18': '1'}).text, \"html5lib\")\n",
    "        post['作者'] = r.find(class_='article-meta-value').text\n",
    "        post['時間'] = r.find_all(class_='article-meta-value')[-1].text\n",
    "        post['時間'] = datetime.strptime(post['時間'], \"%a %b %d %H:%M:%S %Y\")\n",
    "        # 時間轉換：https://stackoverflow.com/questions/10256093/how-to-convert-ctime-to-datetime-in-python\n",
    "        \n",
    "        posts.append(post)\n",
    "    except:\n",
    "        continue\n",
    "        \n",
    "posts = sorted(posts, key= lambda x: x['時間'])\n",
    "posts[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
